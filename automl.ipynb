{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "import csv\r\n",
        "\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn import datasets\r\n",
        "import pkg_resources\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "# Check core SDK version number\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.19.0\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1610553647840
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "experiment = Experiment(workspace=ws, name=\"heart_failure\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = experiment.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FYCFLTTZJ to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Interactive authentication successfully completed.\n",
            "Workspace name: quick-starts-ws-134557\n",
            "Azure region: southcentralus\n",
            "Subscription id: 48a74bb7-9950-4cc1-9caa-5d50f995cc55\n",
            "Resource group: aml-quickstarts-134557\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1610550830121
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "# choose a name for your cluster\r\n",
        "cluster_name = \"cpu-cluster\"\r\n",
        "\r\n",
        "try:\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing compute target')\r\n",
        "except ComputeTargetException:\r\n",
        "    print('Creating a new compute target...')\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \r\n",
        "                                                           min_nodes=1,\r\n",
        "                                                           max_nodes=6)\r\n",
        "\r\n",
        "    # create the cluster\r\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "\r\n",
        "# can poll for a minimum number of nodes and for a specific timeout. \r\n",
        "# if no min node count is provided it uses the scale settings for the cluster\r\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\r\n",
        "\r\n",
        "# use get_status() to get a detailed status for the current cluster. \r\n",
        "print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a new compute target...\n",
            "Creating\n",
            "Succeeded.......................\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n",
            "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 1, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-01-13T16:00:33.911000+00:00', 'errors': None, 'creationTime': '2021-01-13T15:58:23.809338+00:00', 'modifiedTime': '2021-01-13T15:58:39.944742+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 6, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610553645791
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "project_folder = './heart-failure'\r\n",
        "os.makedirs(project_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610550997127
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to load the dataset from the Workspace. Otherwise, create it from the file\r\n",
        "found = False\r\n",
        "key = \"heart-failure-prediction\"\r\n",
        "description_text = \"Heart Failure Prediction dataset\"\r\n",
        "label = \"DEATH_EVENT\"\r\n",
        "if key in ws.datasets.keys(): \r\n",
        "        found = True\r\n",
        "        dataset = ws.datasets[key] \r\n",
        "\r\n",
        "if not found:\r\n",
        "        # Create AML Dataset and register it into Workspace\r\n",
        "        example_data = 'https://raw.githubusercontent.com/heber-augusto/Nanodegree_Azure_ML_Engineer_CapstoneProject/master/data/heart_failure_clinical_records_dataset.csv'\r\n",
        "        dataset = Dataset.Tabular.from_delimited_files(example_data)\r\n",
        "        #Register Dataset in Workspace\r\n",
        "        dataset = dataset.register(workspace=ws,\r\n",
        "                                   name=key,\r\n",
        "                                   description=description_text)\r\n",
        "\r\n",
        "\r\n",
        "df = dataset.to_pandas_dataframe()\r\n",
        "df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610553238926
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(5).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n0  75.0        0                       582         0                 20   \n1  55.0        0                      7861         0                 38   \n2  65.0        0                       146         0                 20   \n3  50.0        1                       111         0                 20   \n4  65.0        1                       160         1                 20   \n\n   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n0                    1  265000.00               1.9           130    1   \n1                    0  263358.03               1.1           136    1   \n2                    0  162000.00               1.3           129    1   \n3                    0  210000.00               1.9           137    1   \n4                    0  327000.00               2.7           116    0   \n\n   smoking  time  DEATH_EVENT  \n0        0     4            1  \n1        0     6            1  \n2        1     7            1  \n3        0     7            1  \n4        0     8            1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>anaemia</th>\n      <th>creatinine_phosphokinase</th>\n      <th>diabetes</th>\n      <th>ejection_fraction</th>\n      <th>high_blood_pressure</th>\n      <th>platelets</th>\n      <th>serum_creatinine</th>\n      <th>serum_sodium</th>\n      <th>sex</th>\n      <th>smoking</th>\n      <th>time</th>\n      <th>DEATH_EVENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75.0</td>\n      <td>0</td>\n      <td>582</td>\n      <td>0</td>\n      <td>20</td>\n      <td>1</td>\n      <td>265000.00</td>\n      <td>1.9</td>\n      <td>130</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55.0</td>\n      <td>0</td>\n      <td>7861</td>\n      <td>0</td>\n      <td>38</td>\n      <td>0</td>\n      <td>263358.03</td>\n      <td>1.1</td>\n      <td>136</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65.0</td>\n      <td>0</td>\n      <td>146</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>162000.00</td>\n      <td>1.3</td>\n      <td>129</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50.0</td>\n      <td>1</td>\n      <td>111</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>210000.00</td>\n      <td>1.9</td>\n      <td>137</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65.0</td>\n      <td>1</td>\n      <td>160</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>327000.00</td>\n      <td>2.7</td>\n      <td>116</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610553274888
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "import pandas as pd\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "# Use the clean_data function to clean your data.\r\n",
        "x = dataset.to_pandas_dataframe()\r\n",
        "x, y = x.pop(label)\r\n",
        "\r\n",
        "# Split data into train and test sets.\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(\r\n",
        "    x, \r\n",
        "    y , \r\n",
        "    test_size=0.33, \r\n",
        "    random_state=42)\r\n",
        "training_data=pd.concat([x_train,y_train], axis=1)\r\n",
        "testing_data=pd.concat([x_test,y_test], axis=1)\r\n",
        "\r\n",
        "\r\n",
        "if not os.path.isdir('data'):\r\n",
        "    os.mkdir('data')\r\n",
        "    \r\n",
        "# Save the train data to a csv to be uploaded to the datastore\r\n",
        "pd.DataFrame(training_data).to_csv(\"data/train_data.csv\", index=False)\r\n",
        "pd.DataFrame(testing_data).to_csv(\"data/test_data.csv\", index=False)\r\n",
        "\r\n",
        "ds = ws.get_default_datastore()\r\n",
        "ds.upload(\r\n",
        "    src_dir='./data', \r\n",
        "    target_path='heart-failure', \r\n",
        "    overwrite=True, \r\n",
        "    show_progress=True)\r\n",
        "\r\n",
        "# Upload the training data as a tabular dataset for access during training on remote compute\r\n",
        "train_data = Dataset.Tabular.from_delimited_files(path=ds.path('heart-failure/train_data.csv'))\r\n",
        "\r\n",
        "test_data = Dataset.Tabular.from_delimited_files(path=ds.path('heart-failure/test_data.csv'))\r\n",
        "label = \"y\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "automl_settings = {\n",
        "    \"experiment_timeout_hours\": 1,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'accuracy'\n",
        "}\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    task='classification',\n",
        "    compute_target=compute_target,\n",
        "    enable_onnx_compatible_models=True,\n",
        "    training_data=train_data,\n",
        "    validation_data=test_data,\n",
        "    label_column_name=label,   \n",
        "    path = project_folder,\n",
        "    enable_early_stopping= True,\n",
        "    featurization= 'auto',\n",
        "    debug_log = \"automl_errors.log\",\n",
        "    **automl_settings)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1610553703757
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
        "\n",
        "ds = ws.get_default_datastore()\n",
        "metrics_output_name = 'metrics_output'\n",
        "best_model_output_name = 'best_model_output'\n",
        "\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=metrics_output_name,\n",
        "                           training_output=TrainingOutput(type='Metrics'))\n",
        "model_data = PipelineData(name='model_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=best_model_output_name,\n",
        "                           training_output=TrainingOutput(type='Model'))"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1610553905225
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_step = AutoMLStep(\r\n",
        "    name='automl_module',\r\n",
        "    automl_config=automl_config,\r\n",
        "    outputs=[metrics_data, model_data],\r\n",
        "    allow_reuse=True)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610553908676
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\r\n",
        "pipeline = Pipeline(\r\n",
        "    description=\"pipeline_with_automlstep\",\r\n",
        "    workspace=ws,    \r\n",
        "    steps=[automl_step])"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610553940187
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run = experiment.submit(pipeline)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created step automl_module [1ba45634][c6a60088-1a62-432f-a71a-58e21d14e994], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun ca64e063-5222-4199-b42a-7fbd58fd0423\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/heart_failure/runs/ca64e063-5222-4199-b42a-7fbd58fd0423?wsid=/subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourcegroups/aml-quickstarts-134557/workspaces/quick-starts-ws-134557\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610553944613
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "RunDetails(pipeline_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7fe0d1493974b03bc26a158aecdfc87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/heart_failure/runs/ca64e063-5222-4199-b42a-7fbd58fd0423?wsid=/subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourcegroups/aml-quickstarts-134557/workspaces/quick-starts-ws-134557\", \"run_id\": \"ca64e063-5222-4199-b42a-7fbd58fd0423\", \"run_properties\": {\"run_id\": \"ca64e063-5222-4199-b42a-7fbd58fd0423\", \"created_utc\": \"2021-01-13T16:05:43.792019Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlstrg134557.blob.core.windows.net/azureml/ExperimentRun/dcid.ca64e063-5222-4199-b42a-7fbd58fd0423/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=%2FyDj5FKelATlG%2Fz%2FDeXmPHERSilDmXpBu1ud6VhTkqQ%3D&st=2021-01-13T16%3A15%3A26Z&se=2021-01-14T00%3A25%3A26Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlstrg134557.blob.core.windows.net/azureml/ExperimentRun/dcid.ca64e063-5222-4199-b42a-7fbd58fd0423/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=qSpHEowDGc8EodoUpwdA5CAQGHRsag7rCHbfJ7jBLco%3D&st=2021-01-13T16%3A15%3A26Z&se=2021-01-14T00%3A25%3A26Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlstrg134557.blob.core.windows.net/azureml/ExperimentRun/dcid.ca64e063-5222-4199-b42a-7fbd58fd0423/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=9eSVCrobmsQBDL%2FQNnxGr7ufsCh%2BZp0fzVDGEHvz0d4%3D&st=2021-01-13T16%3A15%3A26Z&se=2021-01-14T00%3A25%3A26Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:19:43\"}, \"child_runs\": [{\"run_id\": \"\", \"name\": \"automl_module\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-01-13 16:05:49Z] Submitting 1 runs, first five are: 1ba45634:99257324-86ed-49c9-bc0c-e37c887a0ae4\\n\", \"graph\": {\"datasource_nodes\": {\"922d60fb\": {\"node_id\": \"922d60fb\", \"name\": \"heart-failure-prediction\"}}, \"module_nodes\": {\"1ba45634\": {\"node_id\": \"1ba45634\", \"name\": \"automl_module\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"922d60fb\", \"source_node_name\": \"heart-failure-prediction\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"1ba45634\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"\", \"name\": \"automl_module\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1610553954763
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: ca64e063-5222-4199-b42a-7fbd58fd0423\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/heart_failure/runs/ca64e063-5222-4199-b42a-7fbd58fd0423?wsid=/subscriptions/48a74bb7-9950-4cc1-9caa-5d50f995cc55/resourcegroups/aml-quickstarts-134557/workspaces/quick-starts-ws-134557\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:azureml.pipeline.core.run:Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
            "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
            "Please check for package conflicts in your python environment\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\r\n",
        "num_file_downloaded = metrics_output.download('.', show_progress=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "import json\r\n",
        "with open(metrics_output._path_on_datastore) as f:\r\n",
        "    metrics_output_result = f.read()\r\n",
        "    \r\n",
        "deserialized_metrics_output = json.loads(metrics_output_result)\r\n",
        "df = pd.DataFrame(deserialized_metrics_output)\r\n",
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve best model from Pipeline Run\r\n",
        "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\r\n",
        "num_file_downloaded = best_model_output.download('.', show_progress=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\r\n",
        "\r\n",
        "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\r\n",
        "    best_model = pickle.load(f)\r\n",
        "best_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}